\documentclass[aspectratio=169]{beamer}

% Theme and Color Scheme
\usetheme{Madrid}
\usecolortheme{default}

% University of Colorado Boulder Colors
\definecolor{PrimaryColor}{RGB}{207,184,124}
\definecolor{SecondaryColor}{RGB}{0,0,0}
\definecolor{TertiaryColor}{RGB}{86,90,92}
\definecolor{QuaternaryColor}{RGB}{162,164,163}

% Apply color scheme
\setbeamercolor{palette primary}{bg=PrimaryColor,fg=black}
\setbeamercolor{palette secondary}{bg=TertiaryColor,fg=white}
\setbeamercolor{palette tertiary}{bg=SecondaryColor,fg=PrimaryColor}
\setbeamercolor{palette quaternary}{bg=PrimaryColor,fg=black}
\setbeamercolor{structure}{fg=SecondaryColor}
\setbeamercolor{section in toc}{fg=SecondaryColor}
\setbeamercolor{subsection in head/foot}{bg=TertiaryColor,fg=white}

% Title colors
\setbeamercolor{title}{fg=PrimaryColor,bg=SecondaryColor}
\setbeamercolor{frametitle}{fg=black,bg=PrimaryColor}

% Block colors
\setbeamercolor{block title}{bg=PrimaryColor,fg=black}
\setbeamercolor{block body}{bg=QuaternaryColor!20,fg=black}

% Alert block colors
\setbeamercolor{block title alerted}{bg=SecondaryColor,fg=PrimaryColor}
\setbeamercolor{block body alerted}{bg=TertiaryColor!20,fg=black}

% Item colors
\setbeamercolor{item}{fg=PrimaryColor}
\setbeamercolor{subitem}{fg=TertiaryColor}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usepackage{listings}
\usepackage{xcolor}

% Configure listings to handle UTF-8
\lstset{
    inputencoding=utf8,
    extendedchars=true,
    literate=
        {²}{{\textsuperscript{2}}}1
        {³}{{\textsuperscript{3}}}1
        {°}{{\textdegree}}1
        {±}{{\textpm}}1
        {×}{{\texttimes}}1
        {÷}{{\textdiv}}1
        {≤}{{$\leq$}}1
        {≥}{{$\geq$}}1
        {≠}{{$\neq$}}1
        {∞}{{$\infty$}}1
        {α}{{$\alpha$}}1
        {β}{{$\beta$}}1
        {γ}{{$\gamma$}}1
        {δ}{{$\delta$}}1
        {ε}{{$\epsilon$}}1
        {λ}{{$\lambda$}}1
        {μ}{{$\mu$}}1
        {σ}{{$\sigma$}}1
        {π}{{$\pi$}}1
        {→}{{$\rightarrow$}}1
        {←}{{$\leftarrow$}}1
}

% Define CODE macro for Python code
\lstdefinestyle{pythonstyle}{
    language=Python,
    basicstyle=\ttfamily\scriptsize,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{green!50!black}\itshape,
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=5pt,
    backgroundcolor=\color{white},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=single,
    tabsize=4,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    escapeinside={(*@}{@*)},
    xleftmargin=0.5cm,
    xrightmargin=0.5cm,
    inputencoding=utf8,
    extendedchars=true
}

\lstset{style=pythonstyle}

% CODE macro to include external Python files
\newcommand{\CODE}[1]{\lstinputlisting{assets/code/#1}}

% Title Information
\title{CSCA 5642: Introduction to Deep Learning}
\subtitle{University of Colorado Boulder\\ Synthetic Brand Generation with Ensemble Methods}
\author{Dyego Fernandes de Sousa}
\institute{University of Colorado Boulder}
\date{\today}

% Logo on title page
\titlegraphic{\includegraphics[height=1.5cm]{assets/logos/cu_logo.svg}}

% Footer customization
\setbeamertemplate{footline}{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
    \usebeamerfont{author in head/foot}\insertshortauthor
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
    \usebeamerfont{title in head/foot}\insertshorttitle
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,right]{date in head/foot}%
    \usebeamerfont{date in head/foot}\insertshortdate{}\hspace*{2em}
    \insertframenumber{} / \inserttotalframenumber\hspace*{2ex}
  \end{beamercolorbox}}%
  \vskip0pt%
}

\begin{document}

% Title Slide
\begin{frame}
    \titlepage
\end{frame}

\begin{frame}{Problem Statement and Data Overview}
To showcase the application of \textbf{Generative Deep Learning} techniques for synthesizing realistic data.\\
This project is a continuation of my previous works on \textbf{Supervised Learning} and \textbf{Unsupervised Learning}, you can find more information in the appendix.\\

\vspace{1cm}

Detailed ESG (Environmental Social and Governance) dataset to the brand-level\\
\begin{tabular}{|l|r|}
    \hline
    Observations: & \textbf{3605} \\
    \hline
    Features: & \textbf{77} \\
    \hline
\end{tabular}
\end{frame}

\begin{frame}[shrink=10]{ML Approach \& Architecture}
\centering
\begin{tabular}{|l|l|l|p{4cm}|}
    \hline
    \textbf{Model} & \textbf{Type} & \textbf{Purpose} & \textbf{Key Features} \\
    \hline
    CTGAN\textsuperscript{1} & Conditional GAN & Tabular synthesis & Mode-specific normalization, conditional vector \\
    \hline
    TVAE\textsuperscript{2} & Variational Autoencoder & Distribution learning & KL divergence, latent space regularization \\
    \hline
    Gaussian Copula & Statistical & Correlation preservation & Multivariate dependencies \\
    \hline
    GPT-2 Medium & Transformer LLM & Brand name generation & 355M params, fine-tuned \\
    \hline
    Flan-T5 Small & Encoder-Decoder & Conditional text gen & Instruction-following \\
    \hline
\end{tabular}

\vspace{0.2cm}
\textbf{Ensemble Methods}: Combine multiple generators with optimized weighting\\
\textbf{Evaluation Metrics}: Apply statistical tests (KS, correlation) to assess synthetic data quality

\vspace{0.3cm}
\hrule
\vspace{0.1cm}
{\scriptsize \textsuperscript{1} Conditional Tabular Generative Adversarial Networks \quad \textsuperscript{2} Tabular Variational Autoencoders}

\end{frame}


\begin{frame}[shrink=35]{ML Approach & Architecture}

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth,height=0.7\textheight,keepaspectratio]{assets/figures/mermeid1.png}
    \caption{Pipeline}
\end{figure}

\begin{columns}[T]
    \begin{column}{0.5\textwidth}
        \begin{figure}
            \centering
            \includegraphics[width=\textwidth,height=0.6\textheight,keepaspectratio]{assets/figures/mermeid2.png}
            \caption{Ensemble Architecture}
        \end{figure}
    \end{column}
    \begin{column}{0.5\textwidth}
        \begin{figure}
            \centering
            \includegraphics[width=\textwidth,height=0.6\textheight,keepaspectratio]{assets/figures/mermeid3.png}
            \caption{Sequence Diagram}
        \end{figure}
    \end{column}
\end{columns}

\end{frame}

\begin{frame}[fragile]{Data Preprocessing and Exploration}
    Performed Data Cleaning, Handling Missing Values, Encoding Categorical Variables, and Feature Engineering.

    \begin{figure}
        \CODE{cell_016.py}
    \end{figure}
    \begin{figure}
        \CODE{cell_018.py}
    \end{figure}

    \begin{figure}
        \CODE{cell_017.py}
    \end{figure}
\end{frame}


\begin{frame}[shrink=35,fragile]{Hyperparameter Tuning}
    Using Optuna to find optimal hyperparameters for the tabular synthesizers.

    \begin{columns}[T,onlytextwidth]
    \begin{column}{0.5\textwidth}
        \centering
        \begin{figure}
            \CODE{cell_020.py}
        \end{figure}
    \end{column}
    \begin{column}{0.5\textwidth}
        \centering
        \begin{figure}
            \centering
            \includegraphics[width=\textwidth,height=0.6\textheight,keepaspectratio]{assets/figures/figure_001.png}
        \end{figure}

        {\scriptsize
        \textbf{Best Parameters:}\\[0.2cm]
        \begin{tabular}{|l|r|}
            \hline
            \textbf{Parameter} & \textbf{Value} \\
            \hline
            ctgan\_epochs & 500 \\
            tvae\_epochs & 400 \\
            batch\_size & 500 \\
            embedding\_dim & 256 \\
            generator\_dim & [256, 256] \\
            discriminator\_dim & [128, 128] \\
            \hline
        \end{tabular}
        }
    \end{column}
\end{columns}

\end{frame}

\begin{frame}{Training Tabular Ensemble Models}
Training CTGAN, TVAE, and Gaussian Copula models

\begin{columns}[T]
    \begin{column}{0.5\textwidth}
        \centering
        \begin{figure}
            \CODE{cell_022.py}
        \end{figure}
    \end{column}
    \begin{column}{0.5\textwidth}
        \centering
        \begin{figure}
            \CODE{cell_023.py}
        \end{figure}
    \end{column}
\end{columns}
\end{frame}

\begin{frame}[shrink=25]{LLM Ensemble Training}
Training GPT-2 Medium and Flan-T5 for brand name generation

\begin{columns}[T]
    \begin{column}{0.5\textwidth}
        \centering
        \begin{figure}
            \CODE{cell_028.py}
        \end{figure}
    \end{column}
    \begin{column}{0.5\textwidth}
        \centering
        \begin{figure}
            \CODE{cell_029.py}
            \caption{Fine Tuning LLMs}
        \end{figure}
    \end{column}
\end{columns}

    \begin{table}
        \centering
        \begin{tabular}{|l|l|l|l|}
            \hline
            \textbf{Company Name} & \textbf{1st} & \textbf{2nd} & \textbf{3rd} \\
            \hline
            PepsiCo & Coca Cola & Dr Pepper & Snapple's \\
            \hline
            Nestle & Tomatoes & Nutella & Nestle is a manufacturer... \\
            \hline
            Mars, Incorporated & Whole30 & Kashi & Soylent \\
            \hline
        \end{tabular}
        \caption{Generated Brand Names by Model}
    \end{table}
\end{frame}


\begin{frame}[fragile]{Synthetic Data Generation}
    \begin{figure}
        \CODE{cell_033.py}
        \CODE{cell_036.py}
        \caption{Generating Synthetic Tabular Data and Brand Names}
    \end{figure}
\end{frame}

\begin{frame}{Synthetic Data Quality Evaluation}
This phase comprehensively evaluates the quality of generated synthetic data through:
\begin{itemize}
    \item \textbf{Tabular Data}: Prioritizing variance over fidelity for data augmentation.
    \item \textbf{Dimensionality Reduction}: PCA and t-SNE projections
\end{itemize}

    \begin{figure}
        \centering
        \includegraphics[width=0.85\textwidth,height=0.7\textheight,keepaspectratio]{assets/figures/figure_002.png}
    \end{figure}
\end{frame}

\begin{frame}{Distribution Comparison}
    \begin{figure}
        \centering
        \includegraphics[width=0.85\textwidth,height=0.7\textheight,keepaspectratio]{assets/figures/figure_003.png}
    \end{figure}
\end{frame}

\begin{frame}{QQ Plot Comparison}
    \begin{figure}
        \centering
        \includegraphics[width=0.85\textwidth,height=0.7\textheight,keepaspectratio]{assets/figures/figure_005.png}
    \end{figure}
\end{frame}

\begin{frame}{Dimensionality Reduction}
    \begin{figure}
        \centering
        \includegraphics[width=0.85\textwidth,height=0.7\textheight,keepaspectratio]{assets/figures/figure_006.png}
    \end{figure}
\end{frame}

\begin{frame}{Statistical Comparison}
    \begin{figure}
        \centering
        \includegraphics[width=0.85\textwidth,height=0.7\textheight,keepaspectratio]{assets/figures/figure_007.png}
    \end{figure}
\end{frame}


\section{Conclusion}

\begin{frame}[shrink=20]{Conclusions, summary and future work}
\begin{itemize}
    \item Successful implementation of an ensemble-based synthetic data generation pipeline combining tabular synthesizers (CTGAN, TVAE, Gaussian Copula) and LLMs (GPT-2, Flan-T5) to create realistic brand-level ESG datasets.
    \item Trade-offs between fidelity and variance were effectively managed to produce diverse yet representative synthetic data.
    \item Optimal models in production-ready state with scalable architecture for future enhancements.
\end{itemize}

\centering
{\scriptsize
\begin{tabular}{|p{2.5cm}|p{3.5cm}|p{6cm}|}
    \hline
     &  & \textbf{Details} \\
    \hline
    \multirow{\textbf{Worked Well}} & Ensemble Architecture & CTGAN, TVAE, GC complemented; TVAE ~54\% weight (KS: 0.11), GC preserved correlations (MSE: 0.0197) \\
    \cline{2-3}
    & Scalable Pipeline & Stratified generation, conditional synthesis, Google Drive persistence \\
    \cline{2-3}
    & LLM Brand Names & GPT-2 + Flan-T5 achieved 95.4\% success rate, memory-efficient \\
    \hline
    \textbf{Challenges} & LLM Quality Issues & Full sentences, competitor leakage, repetitive patterns, 4.6\% fallback \\
    \hline
    \multirow{\textbf{Future Work}} & Tabular Synthesis & Feature preprocessing, constrained generation, TabDDPM, validation \\
    \cline{2-3}
    & LLM Enhancement & Negative examples, stricter validation, RAG, style conditioning \\
    \cline{2-3}
    & Architecture & Attention-based models, hierarchical pipeline, discriminator filtering \\
    \hline
\end{tabular}
}
\end{frame}


\begin{frame}[shrink=50]{References & Bibliography}
1. \textbf{CTGAN (Conditional Tabular GAN)}
\begin{itemize}
    \item Xu, L., Skoularidou, M., Cuesta-Infante, A., \& Veeramachaneni, K. (2019). \textit{Modeling Tabular Data using Conditional GAN}. NeurIPS 2019.
    \item Paper: https://arxiv.org/abs/1907.00503
    \item Implementation: \href{https://github.com/sdv-dev/SDV}{SDV Library}
\end{itemize}
2. \textbf{TVAE (Tabular Variational Autoencoder)}
\begin{itemize}
    \item Xu, L., Skoularidou, M., Cuesta-Infante, A., \& Veeramachaneni, K. (2019). \textit{Modeling Tabular Data using Conditional GAN}. NeurIPS 2019.
    \item Part of the same paper as CTGAN, presenting VAE-based alternative
\end{itemize}
3. \textbf{Gaussian Copula}
\begin{itemize}
    \item Patki, N., Wedge, R., \& Veeramachaneni, K. (2016). \textit{The Synthetic Data Vault}. IEEE DSAA 2016.
    \item Paper: https://dai.lids.mit.edu/wp-content/uploads/2018/03/SDV.pdf
\end{itemize}
4. \textbf{SDV (Synthetic Data Vault) Library}
\begin{itemize}
    \item Documentation: https://docs.sdv.dev/sdv/
    \item GitHub: https://github.com/sdv-dev/SDV
\end{itemize}

5. \textbf{GPT-2}
\begin{itemize}
    \item Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., \& Sutskever, I. (2019). \textit{Language Models are Unsupervised Multitask Learners}. OpenAI.
    \item Paper: https://cdn.openai.com/better-language-models/language\_models\_are\_unsupervised\_multitask\_learners.pdf
\end{itemize}
6. \textbf{Flan-T5}
\begin{itemize}
    \item Chung, H. W., et al. (2022). \textit{Scaling Instruction-Finetuned Language Models}. arXiv preprint.
    \item Paper: https://arxiv.org/abs/2210.11416
\end{itemize}
7. \textbf{Hugging Face Transformers}
\begin{itemize}
    \item Wolf, T., et al. (2020). \textit{Transformers: State-of-the-Art Natural Language Processing}. EMNLP 2020.
    \item Documentation: https://huggingface.co/docs/transformers/
\end{itemize}

8. \textbf{Kolmogorov-Smirnov Test}
\begin{itemize}
    \item Massey Jr, F. J. (1951). \textit{The Kolmogorov-Smirnov test for goodness of fit}. Journal of the American Statistical Association, 46(253), 68-78.
\end{itemize}
9. \textbf{Silhouette Score}
\begin{itemize}
    \item Rousseeuw, P. J. (1987). \textit{Silhouettes: a graphical aid to the interpretation and validation of cluster analysis}. Journal of Computational and Applied Mathematics, 20, 53-65.
\end{itemize}
10. \textbf{Davies-Bouldin Index}
\begin{itemize}
    \item Davies, D. L., \& Bouldin, D. W. (1979). \textit{A cluster separation measure}. IEEE Transactions on Pattern Analysis and Machine Intelligence, (2), 224-227.
\end{itemize}

11. \textbf{Optuna}
\begin{itemize}
    \item Akiba, T., Sano, S., Yanase, T., Ohta, T., \& Koyama, M. (2019). \textit{Optuna: A Next-generation Hyperparameter Optimization Framework}. KDD 2019.
    \item Paper: https://arxiv.org/abs/1907.10902
    \item Documentation: https://optuna.org/
\end{itemize}

12. \textbf{TabDDPM (Diffusion Models for Tabular Data)}
\begin{itemize}
    \item Kotelnikov, A., Baranchuk, D., Rubachev, I., \& Babenko, A. (2023). \textit{TabDDPM: Modelling Tabular Data with Diffusion Models}. ICML 2023.
    \item Paper: https://arxiv.org/abs/2209.15421
\end{itemize}
13. \textbf{CTAB-GAN+}
\begin{itemize}
    \item Zhao, Z., Kunar, A., Birke, R., \& Chen, L. Y. (2022). \textit{CTAB-GAN+: Enhancing Tabular Data Synthesis}. arXiv preprint.
    \item Paper: https://arxiv.org/abs/2204.00401
\end{itemize}
14. \textbf{Synthetic Data Generation Survey}
\begin{itemize}
    \item Jordon, J., Yoon, J., \& van der Schaar, M. (2022). \textit{Synthetic Data - what, why and how?} arXiv preprint.
    \item Paper: https://arxiv.org/abs/2205.03257
\end{itemize}
\end{frame}

\begin{frame}[shrink]{Appendix \- Other Repositories}
    \begin{itemize}
        \item \textbf{Supervised Learning}: https://github.com/dyegofern/csca5622-supervised-learning
        \item \textbf{Unsupervised Learning}: https://github.com/dyegofern/csca5632-unsupervised-learning
    \end{itemize}
\end{frame}
\begin{frame}[shrink=50]{Appendix \- Mermeid Code}

\begin{columns}[T]
    \begin{column}{0.5\textwidth}
        \centering
        \begin{figure}
            \CODE{mermeid1.md}
        \end{figure}
    \end{column}
    \begin{column}{0.5\textwidth}
        \centering
        \begin{figure}
            \CODE{mermeid2.md}
        \end{figure}

        \centering
        \begin{figure}
            \CODE{mermeid3.md}
        \end{figure}
    \end{column}
\end{columns}

\end{frame}


\begin{frame}[shrink=50]{Appendix \- Tools \& Libraries}
\begin{itemize}
    \item \textbf{PyTorch} - Deep learning framework powering the neural network components of CTGAN and TVAE synthesizers
    \item \textbf{Scikit-learn} - Machine learning utilities for PCA, t-SNE, clustering (AgglomerativeClustering), and evaluation metrics (silhouette score, Davies-Bouldin index)
\end{itemize}

\begin{itemize}
    \item \textbf{SDV (Synthetic Data Vault)} - Primary library for tabular synthetic data generation, providing:
    \item \textbf{CTGAN} - Conditional Tabular GAN for generating realistic tabular data
    \item \textbf{TVAE} - Tabular Variational Autoencoder for distribution-preserving synthesis
    \item \textbf{Gaussian Copula} - Statistical model capturing feature dependencies
\end{itemize}

\begin{itemize}
    \item \textbf{Hugging Face Transformers} - State-of-the-art NLP library for text generation using pre-trained language models
    \item \textbf{PEFT (Parameter-Efficient Fine-Tuning)} - Efficient fine-tuning techniques for large language models
    \item \textbf{BitsAndBytes} - 8-bit quantization for memory-efficient model loading
    \item \textbf{Accelerate} - Distributed training and mixed precision utilities
    \item \textbf{SentencePiece} - Tokenization library for handling text preprocessing
\end{itemize}

\begin{itemize}
    \item \textbf{Optuna} - Automated hyperparameter tuning framework using Bayesian optimization for finding optimal model configurations

    \item \textbf{Pandas} - Data manipulation and analysis
    \item \textbf{NumPy} - Numerical computing and array operations
    \item \textbf{SciPy} - Statistical tests (Kolmogorov-Smirnov test) for distribution comparison
\end{itemize}

\begin{itemize}
    \item \textbf{Matplotlib} - Core plotting library for creating figures
    \item \textbf{Seaborn} - Statistical data visualization with enhanced aesthetics
    \item \textbf{Plotly} - Interactive visualizations (if used)
\end{itemize}

\begin{itemize}
    \item \textbf{Google Colab} - Cloud-based Jupyter notebook environment with GPU support
    \item \textbf{Google Drive} - Persistent storage for models and outputs
\end{itemize}
\end{frame}

\end{document}
