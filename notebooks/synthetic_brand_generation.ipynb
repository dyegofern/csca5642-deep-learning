{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Brand Generation with GANs\n",
    "\n",
    "## Project Goal\n",
    "Generate synthetic brand data to address class imbalance in hierarchical clustering using:\n",
    "- **CTGAN**: For generating realistic brand features (ESG metrics, demographics, business characteristics)\n",
    "- **DistilGPT2**: For generating realistic brand names\n",
    "\n",
    "## Dataset\n",
    "- **Source**: `data/raw/brand_information.csv`\n",
    "- **Size**: 3,605 brands with 80+ features\n",
    "- **Problem**: Hierarchical clustering produces only 2 clusters (severe imbalance)\n",
    "\n",
    "## Notebook Structure\n",
    "1. **Phase 1**: Data Preparation & Exploration\n",
    "2. **Phase 2**: CTGAN Training (Tabular Features)\n",
    "3. **Phase 3**: Brand Name Generation (DistilGPT2)\n",
    "4. **Phase 4**: Synthetic Data Generation\n",
    "5. **Phase 5**: Evaluation & Clustering Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once in Colab)\n",
    "!pip install -q sdv transformers torch pandas numpy scikit-learn matplotlib seaborn plotly scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path (for local imports)\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.append('../src')\n",
    "\n",
    "# Import our custom modules\n",
    "from data_processor import BrandDataProcessor\n",
    "from tabular_gan import TabularBrandGAN\n",
    "from brand_name_generator import BrandNameGenerator\n",
    "from evaluator import BrandDataEvaluator\n",
    "\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ“ All modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (adjust for Colab if needed)\n",
    "DATA_PATH = '../data/raw/brand_information.csv'\n",
    "OUTPUT_DIR = '../data/generated/'\n",
    "MODEL_DIR = '../models/'\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Training parameters\n",
    "CTGAN_EPOCHS = 300\n",
    "CTGAN_BATCH_SIZE = 500\n",
    "GPT2_EPOCHS = 3\n",
    "GPT2_BATCH_SIZE = 8\n",
    "\n",
    "# Generation parameters\n",
    "N_SYNTHETIC_BRANDS = 500  # Total synthetic brands to generate\n",
    "MIN_BRANDS_PER_COMPANY = 3  # Minimum brands a company should have\n",
    "\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Model directory: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 1: Data Preparation & Exploration\n",
    "\n",
    "Load and explore the brand dataset, then prepare it for GAN training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data processor\n",
    "processor = BrandDataProcessor(DATA_PATH)\n",
    "\n",
    "# Load data\n",
    "df = processor.load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "stats = processor.explore_data()\n",
    "\n",
    "# Visualize brands per company\n",
    "brand_counts = pd.Series(stats['brands_per_company'])\n",
    "top_companies = brand_counts.head(20)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "top_companies.plot(kind='bar')\n",
    "plt.title('Top 20 Companies by Number of Brands')\n",
    "plt.xlabel('Company')\n",
    "plt.ylabel('Number of Brands')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCompanies with 1 brand: {(brand_counts == 1).sum()}\")\n",
    "print(f\"Companies with 2+ brands: {(brand_counts >= 2).sum()}\")\n",
    "print(f\"Companies with 5+ brands: {(brand_counts >= 5).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify multi-brand companies (good for training)\n",
    "multi_brand_companies = processor.get_multi_brand_companies(min_brands=3)\n",
    "\n",
    "print(f\"\\nIdentified {len(multi_brand_companies)} companies with 3+ brands\")\n",
    "print(\"\\nExample companies:\")\n",
    "for company in multi_brand_companies[:10]:\n",
    "    n_brands = len(processor.get_company_brands(company))\n",
    "    print(f\"  {company}: {n_brands} brands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "df_clean = processor.clean_data(drop_text_heavy=True)\n",
    "\n",
    "# Check for missing values\n",
    "missing = df_clean.isnull().sum()\n",
    "print(f\"\\nRemaining missing values: {missing[missing > 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for GAN training\n",
    "train_df, val_df = processor.prepare_for_gan(test_size=0.2)\n",
    "\n",
    "print(f\"\\nTraining set shape: {train_df.shape}\")\n",
    "print(f\"Validation set shape: {val_df.shape}\")\n",
    "print(f\"\\nFeatures for GAN: {list(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 2: CTGAN Training (Tabular Features)\n",
    "\n",
    "Train CTGAN to generate realistic brand features conditioned on company name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Initialize and Train CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CTGAN\n",
    "ctgan = TabularBrandGAN(\n",
    "    epochs=CTGAN_EPOCHS,\n",
    "    batch_size=CTGAN_BATCH_SIZE,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Identify discrete columns (categorical features that were encoded)\n",
    "discrete_cols = processor.categorical_features + ['company_name']\n",
    "discrete_cols = [col for col in discrete_cols if col in train_df.columns]\n",
    "\n",
    "print(f\"Discrete columns for CTGAN: {discrete_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CTGAN (this may take 10-30 minutes depending on GPU)\n",
    "ctgan.train(train_df, discrete_columns=discrete_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "ctgan_model_path = os.path.join(MODEL_DIR, 'ctgan_brand_model.pkl')\n",
    "ctgan.save_model(ctgan_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Test CTGAN Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Generate 5 synthetic brands for a specific company\n",
    "test_company = multi_brand_companies[0]\n",
    "test_company_encoded = processor.label_encoders['company_name'].transform([test_company])[0]\n",
    "\n",
    "print(f\"Testing generation for: {test_company} (encoded: {test_company_encoded})\")\n",
    "\n",
    "test_synthetic = ctgan.generate(\n",
    "    n_samples=5,\n",
    "    condition_column='company_name',\n",
    "    condition_value=test_company_encoded\n",
    ")\n",
    "\n",
    "# Decode and display\n",
    "test_decoded = processor.decode_categorical(test_synthetic)\n",
    "test_decoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 3: Brand Name Generation (DistilGPT2)\n",
    "\n",
    "Fine-tune DistilGPT2 to generate realistic brand names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Prepare Brand Name Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataframe with brand_name, company_name, industry_name\n",
    "brand_name_df = df_clean[['brand_name', 'company_name', 'industry_name']].dropna()\n",
    "\n",
    "print(f\"Brand name training data: {len(brand_name_df)} examples\")\n",
    "print(\"\\nExample training data:\")\n",
    "brand_name_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Fine-tune DistilGPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize brand name generator\n",
    "name_generator = BrandNameGenerator(model_name='distilgpt2')\n",
    "\n",
    "# Prepare model\n",
    "name_generator.prepare_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune on brand names (this may take 15-30 minutes)\n",
    "gpt2_output_dir = os.path.join(MODEL_DIR, 'brand_name_generator')\n",
    "\n",
    "name_generator.fine_tune(\n",
    "    brands_df=brand_name_df,\n",
    "    epochs=GPT2_EPOCHS,\n",
    "    batch_size=GPT2_BATCH_SIZE,\n",
    "    output_dir=gpt2_output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Test Brand Name Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Generate brand names for different companies\n",
    "test_companies = [\n",
    "    ('PepsiCo, Inc.', 'Non-Alcoholic Beverages'),\n",
    "    ('Mars, Incorporated', 'Processed Foods'),\n",
    "    ('Nestle', 'Processed Foods')\n",
    "]\n",
    "\n",
    "for company, industry in test_companies:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Company: {company}\")\n",
    "    print(f\"Industry: {industry}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    generated_names = name_generator.generate_brand_names(\n",
    "        company_name=company,\n",
    "        industry_name=industry,\n",
    "        n_names=10,\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    print(\"\\nGenerated brand names:\")\n",
    "    for i, name in enumerate(generated_names, 1):\n",
    "        print(f\"  {i}. {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 4: Synthetic Data Generation\n",
    "\n",
    "Generate synthetic brands combining CTGAN features + DistilGPT2 names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Determine Which Companies Need More Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze current brand distribution\n",
    "brand_counts = df['company_name'].value_counts()\n",
    "\n",
    "# Identify companies with few brands (candidates for augmentation)\n",
    "companies_needing_brands = brand_counts[brand_counts < MIN_BRANDS_PER_COMPANY].index.tolist()\n",
    "\n",
    "print(f\"Companies with < {MIN_BRANDS_PER_COMPANY} brands: {len(companies_needing_brands)}\")\n",
    "print(f\"\\nWe'll generate synthetic brands for {min(50, len(companies_needing_brands))} companies\")\n",
    "\n",
    "# Select top companies to augment (balance between small and medium-sized)\n",
    "target_companies = companies_needing_brands[:50]\n",
    "brands_per_company = max(2, N_SYNTHETIC_BRANDS // len(target_companies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Generate Synthetic Brand Features (CTGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target companies\n",
    "target_companies_encoded = [\n",
    "    processor.label_encoders['company_name'].transform([comp])[0]\n",
    "    for comp in target_companies\n",
    "]\n",
    "\n",
    "# Generate synthetic features for each company\n",
    "synthetic_features = ctgan.generate_for_companies(\n",
    "    companies=target_companies_encoded,\n",
    "    n_per_company=brands_per_company\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(synthetic_features)} synthetic brand feature sets\")\n",
    "synthetic_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Generate Brand Names for Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode categorical features first (so we have company/industry names for generation)\n",
    "synthetic_decoded = processor.decode_categorical(synthetic_features.copy())\n",
    "\n",
    "# Generate brand names\n",
    "print(\"\\nGenerating brand names for synthetic data...\")\n",
    "synthetic_with_names = name_generator.generate_for_dataframe(\n",
    "    synthetic_df=synthetic_decoded,\n",
    "    n_names_per_brand=3,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "print(\"\\nSample synthetic brands:\")\n",
    "synthetic_with_names[['brand_name', 'company_name', 'industry_name']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Save Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save synthetic brands\n",
    "synthetic_path = os.path.join(OUTPUT_DIR, 'synthetic_brands.csv')\n",
    "synthetic_with_names.to_csv(synthetic_path, index=False)\n",
    "print(f\"Synthetic brands saved to: {synthetic_path}\")\n",
    "\n",
    "# Create augmented dataset (original + synthetic)\n",
    "augmented_df = pd.concat([df_clean, synthetic_with_names], ignore_index=True)\n",
    "augmented_path = os.path.join(OUTPUT_DIR, 'augmented_brands.csv')\n",
    "augmented_df.to_csv(augmented_path, index=False)\n",
    "\n",
    "print(f\"\\nAugmented dataset saved to: {augmented_path}\")\n",
    "print(f\"Original brands: {len(df_clean)}\")\n",
    "print(f\"Synthetic brands: {len(synthetic_with_names)}\")\n",
    "print(f\"Total augmented: {len(augmented_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 5: Evaluation & Clustering Comparison\n",
    "\n",
    "Evaluate synthetic data quality and compare clustering results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Statistical Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "evaluator = BrandDataEvaluator()\n",
    "\n",
    "# Compare distributions (using numerical features)\n",
    "numerical_cols = processor.numerical_features[:10]  # Sample of numerical features\n",
    "\n",
    "ks_results = evaluator.compare_distributions(\n",
    "    real_data=df_clean,\n",
    "    synthetic_data=synthetic_with_names,\n",
    "    numerical_cols=numerical_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare correlations\n",
    "real_corr, synth_corr = evaluator.compare_correlations(\n",
    "    real_data=df_clean,\n",
    "    synthetic_data=synthetic_with_names,\n",
    "    numerical_cols=numerical_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution comparisons\n",
    "evaluator.plot_distribution_comparison(\n",
    "    real_data=df_clean,\n",
    "    synthetic_data=synthetic_with_names,\n",
    "    features=numerical_cols[:6]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation heatmaps\n",
    "evaluator.plot_correlation_heatmaps(real_corr, synth_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 PCA Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA comparison\n",
    "evaluator.plot_pca_comparison(\n",
    "    original_data=df_clean,\n",
    "    synthetic_data=synthetic_with_names,\n",
    "    numerical_cols=numerical_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Clustering Comparison (Main Goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare clustering: Original vs Augmented\n",
    "clustering_comparison = evaluator.compare_clustering(\n",
    "    original_data=df_clean,\n",
    "    augmented_data=augmented_df,\n",
    "    numerical_cols=numerical_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cluster distributions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original clustering\n",
    "orig_dist = clustering_comparison['original']['cluster_distribution']\n",
    "ax1.bar(orig_dist.keys(), orig_dist.values())\n",
    "ax1.set_title('Original Data: Cluster Sizes')\n",
    "ax1.set_xlabel('Cluster')\n",
    "ax1.set_ylabel('Number of Brands')\n",
    "\n",
    "# Augmented clustering\n",
    "aug_dist = clustering_comparison['augmented']['cluster_distribution']\n",
    "ax2.bar(aug_dist.keys(), aug_dist.values())\n",
    "ax2.set_title('Augmented Data: Cluster Sizes')\n",
    "ax2.set_xlabel('Cluster')\n",
    "ax2.set_ylabel('Number of Brands')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Generate Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display report\n",
    "report = evaluator.generate_report()\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "report_path = os.path.join(OUTPUT_DIR, 'evaluation_report.txt')\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report)\n",
    "print(f\"\\nReport saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SYNTHETIC BRAND GENERATION: FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nðŸ“Š Dataset Statistics:\")\n",
    "print(f\"  Original brands: {len(df_clean)}\")\n",
    "print(f\"  Synthetic brands generated: {len(synthetic_with_names)}\")\n",
    "print(f\"  Augmented dataset total: {len(augmented_df)}\")\n",
    "print(f\"  Augmentation ratio: {len(synthetic_with_names)/len(df_clean)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Clustering Results:\")\n",
    "orig = clustering_comparison['original']\n",
    "aug = clustering_comparison['augmented']\n",
    "print(f\"  Original - Clusters: {orig['n_clusters']}, Silhouette: {orig['silhouette_score']:.4f}\")\n",
    "print(f\"  Augmented - Clusters: {aug['n_clusters']}, Silhouette: {aug['silhouette_score']:.4f}\")\n",
    "print(f\"  Improvement: {clustering_comparison['silhouette_improvement']:+.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ“ Output Files:\")\n",
    "print(f\"  Synthetic brands: {synthetic_path}\")\n",
    "print(f\"  Augmented dataset: {augmented_path}\")\n",
    "print(f\"  CTGAN model: {ctgan_model_path}\")\n",
    "print(f\"  Name generator: {gpt2_output_dir}\")\n",
    "print(f\"  Evaluation report: {report_path}\")\n",
    "\n",
    "print(\"\\nâœ… Pipeline completed successfully!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Optional: Load Pre-trained Models\n",
    "\n",
    "If you want to skip training and load previously saved models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CTGAN model\n",
    "# ctgan = TabularBrandGAN()\n",
    "# ctgan.load_model(ctgan_model_path)\n",
    "\n",
    "# Load brand name generator\n",
    "# name_generator = BrandNameGenerator()\n",
    "# name_generator.load_model(gpt2_output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}