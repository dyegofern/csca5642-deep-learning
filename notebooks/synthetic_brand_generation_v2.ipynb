{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Brand Generation V2 - Enhanced with Ensemble Methods\n",
    "\n",
    "### University of Colorado Boulder - Introduction to Deep Learning\n",
    "---\n",
    "#### Dyego Fernandes de Sousa\n",
    "---\n",
    "\n",
    "### Improvements over V1\n",
    "\n",
    "This notebook implements the following enhancements:\n",
    "\n",
    "1. **TVAE (Tabular Variational Autoencoder)**: Alternative to CTGAN for better continuous distributions\n",
    "2. **Gaussian Copula**: For better correlation structure preservation\n",
    "3. **Larger Language Models**: GPT-2 Medium, Flan-T5, Phi-2, TinyLlama for improved brand name generation\n",
    "4. **Ensemble Methods**: Voting/averaging across multiple generators\n",
    "\n",
    "### Notebook Structure\n",
    "1. **Phase 1**: Setup & Data Preparation\n",
    "2. **Phase 2**: Tabular Ensemble Training (CTGAN + TVAE + Gaussian Copula)\n",
    "3. **Phase 3**: LLM Ensemble Training (GPT-2 Medium + Flan-T5)\n",
    "4. **Phase 4**: Synthetic Data Generation with Ensembles\n",
    "5. **Phase 5**: Quality Evaluation & Comparison (V1 vs V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Setup & Installation\n",
    "\n",
    "### Optimized for Google Colab Pro (~15GB RAM, ~16GB VRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository and install dependencies\n",
    "!git clone https://github.com/dyegofern/csca5642-deep-learning.git\n",
    "!pip install -q sdv transformers torch pandas numpy scikit-learn matplotlib seaborn plotly scipy\n",
    "!pip install -q peft bitsandbytes accelerate sentencepiece  # Additional V2 dependencies\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "MAPPED_DIR = '/content/csca5642-deep-learning'\n",
    "\n",
    "# Mount Google Drive\n",
    "print(\"Mounting Google Drive...\")\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "else:\n",
    "    print(\"Google Drive already mounted\")\n",
    "\n",
    "DATA_PATH = MAPPED_DIR + '/data/raw/brand_information.csv'\n",
    "\n",
    "# Set output and model directories to Google Drive\n",
    "DRIVE_OUTPUT_BASE = '/content/drive/MyDrive/Colab_Output/SyntheticBrandGeneration_V2'\n",
    "OUTPUT_DIR = os.path.join(DRIVE_OUTPUT_BASE, 'outputs')\n",
    "MODEL_DIR = os.path.join(DRIVE_OUTPUT_BASE, 'models')\n",
    "\n",
    "# Create directories\n",
    "print(f\"\\nCreating directories in Google Drive...\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Model directory: {MODEL_DIR}\")\n",
    "\n",
    "# Add src to path\n",
    "src_path = MAPPED_DIR + '/src'\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "print(f\"\\nSetup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import V2 modules\n",
    "from data_processor import BrandDataProcessor\n",
    "from tabular_gan_v2 import (\n",
    "    EnsembleSynthesizer,\n",
    "    CTGANSynthesizerWrapper,\n",
    "    TVAESynthesizerWrapper,\n",
    "    GaussianCopulaSynthesizerWrapper,\n",
    "    calculate_generation_targets\n",
    ")\n",
    "from brand_name_generator_v2 import BrandNameGeneratorV2\n",
    "from evaluator import BrandDataEvaluator\n",
    "\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Check GPU\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "print(\"\\nAll V2 modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for V2\n",
    "FROM_PRETRAINED = False  # Set to True to load pre-trained models\n",
    "\n",
    "# Tabular Ensemble Config\n",
    "CTGAN_EPOCHS = 300\n",
    "TVAE_EPOCHS = 300\n",
    "BATCH_SIZE = 500\n",
    "ENSEMBLE_WEIGHTS = {\n",
    "    'ctgan': 0.40,\n",
    "    'tvae': 0.35,\n",
    "    'gaussian_copula': 0.25\n",
    "}\n",
    "\n",
    "# LLM Ensemble Config\n",
    "LLM_MODELS = ['gpt2-medium', 'flan-t5-base']  # Can add 'phi-2', 'tinyllama' if memory allows\n",
    "LLM_EPOCHS = 3\n",
    "\n",
    "# Generation Config\n",
    "MIN_BRANDS_PER_COMPANY = 10\n",
    "DIVERSITY_TEMPERATURE = 0.7\n",
    "ADD_DIVERSITY_NOISE = True\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  FROM_PRETRAINED: {FROM_PRETRAINED}\")\n",
    "print(f\"  CTGAN_EPOCHS: {CTGAN_EPOCHS}\")\n",
    "print(f\"  TVAE_EPOCHS: {TVAE_EPOCHS}\")\n",
    "print(f\"  LLM_MODELS: {LLM_MODELS}\")\n",
    "print(f\"  ENSEMBLE_WEIGHTS: {ENSEMBLE_WEIGHTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "processor = BrandDataProcessor(DATA_PATH)\n",
    "raw_data = processor.load_data()\n",
    "print(f\"Loaded {len(raw_data)} brands with {len(raw_data.columns)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "cleaned_data = processor.clean_data()\n",
    "print(f\"\\nCleaned data: {len(cleaned_data)} rows, {len(cleaned_data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for GAN training\n",
    "train_df, val_df = processor.prepare_for_gan(test_size=0.2)\n",
    "\n",
    "print(f\"\\nTraining set: {len(train_df)} brands\")\n",
    "print(f\"Validation set: {len(val_df)} brands\")\n",
    "\n",
    "# Get column types\n",
    "discrete_cols = processor.categorical_features\n",
    "binary_cols = [col for col in train_df.columns if train_df[col].nunique() == 2 and set(train_df[col].unique()).issubset({0, 1})]\n",
    "numerical_cols = [col for col in train_df.columns if col not in discrete_cols and col not in binary_cols]\n",
    "\n",
    "print(f\"\\nColumn types:\")\n",
    "print(f\"  Numerical: {len(numerical_cols)}\")\n",
    "print(f\"  Categorical: {len(discrete_cols)}\")\n",
    "print(f\"  Binary: {len(binary_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Tabular Ensemble Training\n",
    "\n",
    "Training CTGAN, TVAE, and Gaussian Copula models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ensemble Synthesizer\n",
    "tabular_ensemble = EnsembleSynthesizer(\n",
    "    ctgan_epochs=CTGAN_EPOCHS,\n",
    "    ctgan_batch_size=BATCH_SIZE,\n",
    "    tvae_epochs=TVAE_EPOCHS,\n",
    "    tvae_batch_size=BATCH_SIZE,\n",
    "    gc_default_distribution='beta',\n",
    "    weights=ENSEMBLE_WEIGHTS,\n",
    "    verbose=True,\n",
    "    cuda=True\n",
    ")\n",
    "\n",
    "print(\"Tabular Ensemble initialized with:\")\n",
    "print(f\"  - CTGAN (epochs={CTGAN_EPOCHS})\")\n",
    "print(f\"  - TVAE (epochs={TVAE_EPOCHS})\")\n",
    "print(f\"  - Gaussian Copula (distribution=beta)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FROM_PRETRAINED:\n",
    "    # Load pre-trained models\n",
    "    print(\"Loading pre-trained tabular ensemble...\")\n",
    "    tabular_ensemble.load_models(os.path.join(MODEL_DIR, 'tabular_ensemble'))\n",
    "else:\n",
    "    # Train all models\n",
    "    print(\"Training tabular ensemble (this will take ~30-60 minutes)...\")\n",
    "    training_times = tabular_ensemble.train(\n",
    "        data=train_df,\n",
    "        discrete_columns=discrete_cols,\n",
    "        binary_columns=binary_cols\n",
    "    )\n",
    "    \n",
    "    # Save models\n",
    "    tabular_ensemble.save_models(os.path.join(MODEL_DIR, 'tabular_ensemble'))\n",
    "    \n",
    "    print(f\"\\nTraining times:\")\n",
    "    for model, time in training_times.items():\n",
    "        print(f\"  {model}: {time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare individual model quality\n",
    "print(\"Evaluating individual model quality...\")\n",
    "comparison_df = tabular_ensemble.compare_all_models(train_df, n_samples=1000)\n",
    "print(\"\\nModel Comparison:\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally optimize weights based on quality\n",
    "# optimized_weights = tabular_ensemble.optimize_weights(train_df, n_eval_samples=1000)\n",
    "# print(f\"Optimized weights: {optimized_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: LLM Ensemble Training\n",
    "\n",
    "Training GPT-2 Medium and Flan-T5 for brand name generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare brand name training data\n",
    "brands_df = processor.raw_data[['brand_name', 'company_name', 'industry_name']].dropna()\n",
    "print(f\"Brand name training data: {len(brands_df)} examples\")\n",
    "brands_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM Ensemble Generator\n",
    "llm_generator = BrandNameGeneratorV2(\n",
    "    models=LLM_MODELS,\n",
    "    memory_efficient=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"LLM Ensemble initialized with models: {LLM_MODELS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FROM_PRETRAINED:\n",
    "    # Load pre-trained models\n",
    "    print(\"Loading pre-trained LLM ensemble...\")\n",
    "    llm_generator.load_model(os.path.join(MODEL_DIR, 'llm_ensemble'))\n",
    "else:\n",
    "    # Fine-tune all models\n",
    "    print(f\"Fine-tuning LLM ensemble (epochs={LLM_EPOCHS})...\")\n",
    "    print(\"This will train each model sequentially to save memory.\")\n",
    "    \n",
    "    llm_generator.fine_tune(\n",
    "        brands_df=brands_df,\n",
    "        epochs=LLM_EPOCHS,\n",
    "        output_dir=os.path.join(MODEL_DIR, 'llm_ensemble')\n",
    "    )\n",
    "    \n",
    "    # Save ensemble config\n",
    "    llm_generator.save_model(os.path.join(MODEL_DIR, 'llm_ensemble'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LLM generation\n",
    "print(\"Testing LLM ensemble generation...\")\n",
    "llm_generator.prepare_model()\n",
    "\n",
    "test_companies = [\n",
    "    (\"Apple\", \"Technology\"),\n",
    "    (\"Nike\", \"Apparel\"),\n",
    "    (\"Nestle\", \"Food & Beverage\")\n",
    "]\n",
    "\n",
    "for company, industry in test_companies:\n",
    "    names = llm_generator.generate_brand_names(company, industry, n_names=3)\n",
    "    print(f\"\\n{company} ({industry}): {names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate generation targets\n",
    "generation_targets = calculate_generation_targets(\n",
    "    data=train_df,\n",
    "    company_column='company_name',\n",
    "    min_brands_per_company=MIN_BRANDS_PER_COMPANY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic tabular features using ensemble\n",
    "print(\"Generating synthetic features with ensemble...\")\n",
    "synthetic_features, failed_companies = tabular_ensemble.generate_stratified(\n",
    "    company_distribution=generation_targets,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(synthetic_features)} synthetic brand features\")\n",
    "if failed_companies:\n",
    "    print(f\"Failed companies: {len(failed_companies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add diversity noise if enabled\n",
    "if ADD_DIVERSITY_NOISE:\n",
    "    print(\"Adding diversity noise to numerical features...\")\n",
    "    synthetic_features = tabular_ensemble.add_diversity_noise(\n",
    "        synthetic_features,\n",
    "        noise_level=0.02\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode categorical features back to original values\n",
    "print(\"Decoding categorical features...\")\n",
    "synthetic_decoded = processor.decode_categorical(synthetic_features)\n",
    "print(f\"Decoded {len(synthetic_decoded)} synthetic brands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate brand names using LLM ensemble\n",
    "print(\"\\nGenerating brand names with LLM ensemble...\")\n",
    "llm_generator.reset_uniqueness_tracker()\n",
    "\n",
    "synthetic_with_names = llm_generator.generate_for_dataframe(\n",
    "    synthetic_df=synthetic_decoded,\n",
    "    temperature=DIVERSITY_TEMPERATURE,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal synthetic dataset: {len(synthetic_with_names)} brands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview synthetic data\n",
    "print(\"\\nSample of generated synthetic brands:\")\n",
    "display(synthetic_with_names[['company_name', 'industry_name', 'brand_name']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save synthetic data\n",
    "synthetic_path = os.path.join(OUTPUT_DIR, 'synthetic_brands_v2.csv')\n",
    "synthetic_with_names.to_csv(synthetic_path, index=False)\n",
    "print(f\"Synthetic data saved to {synthetic_path}\")\n",
    "\n",
    "# Create augmented dataset\n",
    "original_decoded = processor.decode_categorical(train_df)\n",
    "augmented_df = pd.concat([original_decoded, synthetic_with_names], ignore_index=True)\n",
    "\n",
    "augmented_path = os.path.join(OUTPUT_DIR, 'augmented_brands_v2.csv')\n",
    "augmented_df.to_csv(augmented_path, index=False)\n",
    "print(f\"Augmented data saved to {augmented_path}\")\n",
    "print(f\"Total augmented size: {len(augmented_df)} brands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: Quality Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "evaluator = BrandDataEvaluator()\n",
    "\n",
    "# Get numerical columns for evaluation\n",
    "eval_numerical_cols = [col for col in numerical_cols if col in synthetic_features.columns and col in train_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution comparison\n",
    "print(\"\\n=== Distribution Comparison (KS Test) ===\")\n",
    "ks_results = evaluator.compare_distributions(train_df, synthetic_features, eval_numerical_cols)\n",
    "\n",
    "# Count passes\n",
    "passes = sum(1 for v in ks_results.values() if v['pvalue'] > 0.05)\n",
    "print(f\"\\nKS Test Summary: {passes}/{len(ks_results)} features pass (p > 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation comparison\n",
    "print(\"\\n=== Correlation Comparison ===\")\n",
    "real_corr, synth_corr = evaluator.compare_correlations(train_df, synthetic_features, eval_numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions\n",
    "print(\"\\n=== Distribution Visualization ===\")\n",
    "evaluator.plot_distribution_comparison(train_df, synthetic_features, eval_numerical_cols[:6])\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'distribution_comparison_v2.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmaps\n",
    "print(\"\\n=== Correlation Heatmaps ===\")\n",
    "evaluator.plot_correlation_heatmaps(train_df, synthetic_features, eval_numerical_cols)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'correlation_comparison_v2.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization\n",
    "print(\"\\n=== PCA Visualization ===\")\n",
    "evaluator.plot_pca_comparison(train_df, synthetic_features, eval_numerical_cols)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'pca_comparison_v2.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering evaluation\n",
    "print(\"\\n=== Clustering Evaluation ===\")\n",
    "cluster_metrics = evaluator.evaluate_clustering(train_df, eval_numerical_cols)\n",
    "print(f\"Original data clustering - Silhouette: {cluster_metrics['silhouette']:.3f}\")\n",
    "\n",
    "augmented_cluster_metrics = evaluator.evaluate_clustering(augmented_df, eval_numerical_cols)\n",
    "print(f\"Augmented data clustering - Silhouette: {augmented_cluster_metrics['silhouette']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=\"*60)\n",
    "print(\"SYNTHETIC BRAND GENERATION V2 - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOriginal dataset: {len(train_df)} brands\")\n",
    "print(f\"Synthetic generated: {len(synthetic_with_names)} brands\")\n",
    "print(f\"Augmented total: {len(augmented_df)} brands\")\n",
    "print(f\"\\nModels used:\")\n",
    "print(f\"  Tabular: CTGAN + TVAE + Gaussian Copula (ensemble)\")\n",
    "print(f\"  Text: {', '.join(LLM_MODELS)} (ensemble)\")\n",
    "print(f\"\\nQuality metrics:\")\n",
    "print(f\"  KS Test pass rate: {passes}/{len(ks_results)} ({100*passes/len(ks_results):.1f}%)\")\n",
    "print(f\"  Clustering silhouette (augmented): {augmented_cluster_metrics['silhouette']:.3f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"GPU memory cleared\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
